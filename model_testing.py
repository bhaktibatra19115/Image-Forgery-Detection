# -*- coding: utf-8 -*-
"""model_testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AyLLaV45fHRY8sWTjTy5Y5QjkTYsLYaM

#Loss Plot
"""

loss=pd.read_csv('SRM_12_2.csv')
loss.head()

loss=pd.read_csv('SRM_loss.csv')
loss.head()

epochs=loss['Unnamed: 0']
los =loss['0']

epochs=loss['Unnamed: 0']
los =loss['0']

plt.title('Loss Plot')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.plot(epochs,los)

plt.title('Loss Plot')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.plot(epochs,los)







import pandas as pd
import pandas as pd
import cv2
import matplotlib.pyplot as plt
from tqdm import tqdm
import pickle
import numpy as np
import random
from sklearn.model_selection import cross_val_score
!pip install catboost
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier
import xgboost as xgb
from catboost import CatBoostClassifier
from sklearn.svm import NuSVC

"""# features read"""

train_features=pd.read_csv('/content/drive/My Drive/SML _ PROJECT/bhakti_train')
test_features=pd.read_csv('/content/drive/My Drive/SML _ PROJECT/bhakti_test')

train_features

Y_train=train_features['Label']
X_train=train_features.drop(['Label','images'],axis=1)
Y_test=test_features['Label']#for checking
X_test=test_features.drop(['Label','images'],axis=1)



"""# Feature Analysis on 8 Patch Model"""

svm=SVC(gamma=0.0001,C=1000)
xg=xgb.XGBClassifier(booster='gbtree',eta=0.1)
lg=LGBMClassifier(objective='binary', boosting='gbdt',learning_rate = 0.1)
cb=CatBoostClassifier(iterations=935,learning_rate=0.1)

def cv_checker(classifier , train , label):
  results=[]
  Xt = train
  y = label
  skf = StratifiedKFold(n_splits=5)
  acc=cross_val_score(classifier, Xt, y, cv=skf,scoring='accuracy')
  print(acc)
  results.append(acc)
  print(acc.mean())
  print(acc.std())
  return results

r4=cv_checker(lf,X_train,Y_train)

r3=cv_checker(cb,X_train,Y_train)

r2=cv_checker(lg,X_train,Y_train)

r1=cv_checker(xg,X_train,Y_train)

r=cv_checker(svm,X_train,Y_train)

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn import model_selection
models = []
models.append(('LR', LogisticRegression()))
models.append(('SVM', SVC()))
results = []
names = []
scoring = 'accuracy'
X= np.array(data)
Y=np.array(label)
for name, model in models:
	skf = StratifiedKFold(n_splits=5)
	cv_results = model_selection.cross_val_score(model, X, Y, cv=skf, scoring=scoring)
	results.append(cv_results)
	names.append(name)
	msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
	print(msg)
# boxplot algorithm comparison



"""catboost"""

clf = CatBoostClassifier( iterations=933,learning_rate=0.1,custom_loss=['AUC', 'Accuracy'])

clf.fit(X_train,Y_train,verbose=True,
          eval_set=(X_test, Y_test),
        plot=True )

print('CatBoost model is fitted: ' + str(clf.is_fitted()))
print('CatBoost model parameters:')
print(clf.get_params())

"""stacking classifier"""

estimators = [
    ('svm',SVC(gamma=0.0001,C=1000)),
    # ('xgb_t',xgb.XGBClassifier(booster='gbtree',eta=0.1)),
    # ('lg' , LGBMClassifier(objective='binary', boosting='gbdt',learning_rate = 0.1)),
    ('cb',CatBoostClassifier(iterations=935,learning_rate=0.1)) ]

lf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(),cv=5)
# lf.fit()



from lightgbm import LGBMClassifier
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn import model_selection
from sklearn.svm import SVC

results=np.array([0.74259558 ,0.76036618, 0.9095315,  0.90786638, 0.921875  ])
results.mean()

import matplotlib.pyplot as plt
fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(l1)
ax.set_xticklabels(name)
plt.show()

l1=[]

l1.append(r4)

name=['svm','xgb','lgb','cat','ensemble','cat+svm']

import matplotlib.pyplot as plt
fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(l1)
ax.set_xticklabels(name)
plt.show()

ma=[0.7462131287950532, 0.6995621181735465, 0.7740093982693628, 0.7670059583495813, 0.7927546399457783, 0.7775640981003844, 0.818070430152452, 0.7979253128887899, 0.8316444766308285, 0.8199020945908307, 0.8414463330733664, 0.8381072085120606 ,0.8442463743895419 ,0.8551271516907135]
c = ['0.001', '0.01', '0.1', '1', '10', '100', '1000']
gamma = [0.001,0.0001]

plt.title('Gamma = 0.001')
plt.ylabel('mean accuracies')
plt.xlabel('C')
plt.bar(c,ma[:7],width=0.55)

import matplotlib.pyplot as plt

plt.title('Gamma = 0.0001')
plt.ylabel('mean accuracies')
plt.xlabel('C')
# plt.bar(c,ma[:7])
plt.bar(c,ma[7:14], width = 0.55)



"""# Feature ANALYSIS of 2 patch model"""

train_features=pd.read_csv('/content/drive/My Drive/SML _ PROJECT/train_patch2_features.csv')
test_features=pd.read_csv('/content/drive/My Drive/SML _ PROJECT/test_patch2_features.csv')
Y_train=train_features['labels']
X_train=train_features.drop(['labels','image_names'],axis=1)
Y_test=test_features['labels']#for checking
X_test=test_features.drop(['labels','image_names'],axis=1)

train_features.head()

svm=SVC(gamma=0.0001,C=1000)
xg=xgb.XGBClassifier(booster='gbtree',eta=0.1)
lg=LGBMClassifier(objective='binary', boosting='gbdt',learning_rate = 0.1)
cb=CatBoostClassifier(iterations=935,learning_rate=0.1)

estimators = [
    ('svm',SVC(gamma=0.0001,C=1000)),
    ('xgb_t',xgb.XGBClassifier(booster='gbtree',eta=0.1)),
    ('lg' , LGBMClassifier(objective='binary', boosting='gbdt',learning_rate = 0.1)),
    ('cb',CatBoostClassifier(iterations=935,learning_rate=0.1)) ]

ensemble = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(),cv=2)
# lf.fit()

estimators = [
    ('svm',SVC(gamma=0.0001,C=1000)),
    # ('xgb_t',xgb.XGBClassifier(booster='gbtree',eta=0.1)),
    # ('lg' , LGBMClassifier(objective='binary', boosting='gbdt',learning_rate = 0.1)),
    ('cb',CatBoostClassifier(iterations=935,learning_rate=0.1)) ]

ensemble2 = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(),cv=5)
# lf.fit()

results=[]

r1=cv_checker(svm,X_train,Y_train)
results.append(r1)
r2=cv_checker(xg,X_train,Y_train)
results.append(r2)
r3=cv_checker(lg,X_train,Y_train)
results.append(r3)
r4=cv_checker(cb,X_train,Y_train)
results.append(r4)
r5=cv_checker(ensemble,X_train,Y_train)
results.append(r5)
r6=cv_checker(ensemble2,X_train,Y_train)
results.append(r6)

import matplotlib.pyplot as plt
fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(r)
ax.set_xticklabels(name)
plt.show()

results

results[1][0]

r=[]
for i in range(6):
  r.append(results[i][0])



"""#feature analysis of mask gen model"""

train_features=pd.read_csv('/content/drive/My Drive/SML _ PROJECT/features.csv')
# test_features=pd.read_csv('/content/drive/My Drive/SML _ PROJECT/test_patch2_features.csv')
Y_train=train_features['labels']
X_train=train_features.drop(['labels','image_names'],axis=1)
# Y_test=test_features['labels']#for checking
# X_test=test_features.drop(['labels','image_names'],axis=1)

results=[]

r1=cv_checker(svm,X_train,Y_train)
results.append(r1)
r2=cv_checker(xg,X_train,Y_train)
results.append(r2)
r3=cv_checker(lg,X_train,Y_train)
results.append(r3)
r4=cv_checker(cb,X_train,Y_train)
results.append(r4)
r5=cv_checker(ensemble,X_train,Y_train)
results.append(r5)
r6=cv_checker(ensemble2,X_train,Y_train)
results.append(r6)

results

import matplotlib.pyplot as plt
fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(r)
ax.set_xticklabels(name)
plt.show()



